services:
  llm-defender-validator:
    depends_on: 
      - prompt-generation-api
    restart: unless-stopped
    build:
      context: .
      dockerfile: validator.Dockerfile
    command: /bin/bash -c "source /tmp/.venv/bin/activate && pip install -e /var/run/llm-defender-subnet[validator] && python3 /var/run/llm-defender-subnet/llm_defender/neurons/validator.py --netuid ${NETUID} --subtensor.network ${SUBTENSOR_NETWORK} --subtensor.chain_endpoint ${SUBTENSOR_CHAIN_ENDPOINT} --wallet.name ${VALIDATOR_WALLET} --wallet.hotkey ${VALIDATOR_HOTKEY} --log_level ${LOG_LEVEL}"
    volumes:
      - ./:/var/run/llm-defender-subnet/
      - llm-defender-subnet:/root/.llm-defender-subnet
      - ~/.bittensor/:/root/
  prompt-generation-api:
    restart: unless-stopped
    image: vllm/vllm-openai:v0.5.0
    ports:
      - "8000:8000"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    ipc: host
    command: [
      "--model", "TheBloke/Mixtral-8x7B-Instruct-v0.1-GPTQ",
      "--revision", "gptq-8bit-128g-actorder_True",
      "--tensor-parallel-size", "4"
    ]

volumes:
  llm-defender-subnet: